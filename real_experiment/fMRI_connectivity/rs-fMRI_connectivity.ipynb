{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import pickle\n",
    "from SPD_SURE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_cluster(corr, label, threshold = 0.5, n_node = None, plot = False):\n",
    "    #corr = corr.to_numpy()\n",
    "    \n",
    "    corr[corr > 1] = 1\n",
    "    corr[corr < -1] = -1\n",
    "    \n",
    "    # force to be symmetric\n",
    "    corr = (corr + corr.T)/2\n",
    "\n",
    "    if n_node == None:\n",
    "        n_node = corr.shape[0]\n",
    "    dissimilarity = 1 - np.abs(corr)\n",
    "    hierarchy = linkage(squareform(dissimilarity), method='average')\n",
    "    ind = fcluster(hierarchy, threshold*corr.max(), criterion='distance')\n",
    "    \n",
    "    order = np.argsort(ind)[::-1][:n_node]\n",
    "\n",
    "    columns = [label[i] for i in list((order))]\n",
    "    corr_ = corr[:, order][order]\n",
    "    if plot:\n",
    "        # Plot the correlation matrix\n",
    "        fig_size = 10\n",
    "        fig, ax = plt.subplots(figsize=(fig_size, fig_size))\n",
    "        cax = ax.matshow(corr_, cmap='RdYlGn')\n",
    "        plt.xticks(range(len(columns)), columns, rotation=90);\n",
    "        plt.yticks(range(len(columns)), columns);\n",
    "\n",
    "        # Add the colorbar legend\n",
    "        cbar = fig.colorbar(cax, ticks=[-1, 0, 1], aspect=40, shrink=.8)\n",
    "    \n",
    "    return ind\n",
    "\n",
    "def check_SPD(X):\n",
    "    # X be a n x N x N array\n",
    "    # check if X[i]'s are SPD\n",
    "    n = X.shape[0]\n",
    "    N = X.shape[1]\n",
    "    I = np.eye(N)\n",
    "    res = np.zeros(X.shape)\n",
    "    for i in range(n):\n",
    "        min_eigval = np.min(np.linalg.eigvalsh(X[i]))\n",
    "        if min_eigval < 0:\n",
    "            res[i] = X[i] + (abs(min_eigval) + 1e-3)*I\n",
    "        else:\n",
    "            res[i] = X[i]\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADHD200_CC200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_pool\n",
       "Typically Developing          330\n",
       "ADHD-Combined                 109\n",
       "ADHD-Inattentive               74\n",
       "ADHD-Hyperactive/Impulsive      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_list = pd.read_csv('UMCD_dataset/ADHD200_CC200/ADHD200_CC200_list.csv', header = 0)\n",
    "sub_id = sub_list['network_name']\n",
    "\n",
    "sub_list.value_counts('subject_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_list = glob.glob('UMCD_dataset/ADHD200_CC200/ADHD200_CC200/*_connectivity_matrix*.txt')\n",
    "con_mat_TD = []\n",
    "con_mat_ADHD_C = []\n",
    "con_mat_ADHD_I = []\n",
    "\n",
    "for i in sub_id:\n",
    "    fname = 'UMCD_dataset/ADHD200_CC200/ADHD200_CC200/' + i + '_connectivity_matrix_file.txt'\n",
    "    if not os.path.isfile(fname):\n",
    "        continue\n",
    "    con_mat = np.loadtxt(fname)\n",
    "    np.fill_diagonal(con_mat, 1)  \n",
    "    if sub_list.loc[sub_list['network_name'] == i].subject_pool.item() == 'Typically Developing':\n",
    "        con_mat_TD.append(con_mat)\n",
    "    elif sub_list.loc[sub_list['network_name'] == i].subject_pool.item() == 'ADHD-Combined':\n",
    "        con_mat_ADHD_C.append(con_mat)\n",
    "    elif sub_list.loc[sub_list['network_name'] == i].subject_pool.item() == 'ADHD-Inattentive':\n",
    "        con_mat_ADHD_I.append(con_mat)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    \n",
    "\n",
    "con_mat_TD = np.array(con_mat_TD)\n",
    "mean_con_mat_TD = np.mean(con_mat_TD, axis = 0)\n",
    "\n",
    "con_mat_ADHD_C = np.array(con_mat_ADHD_C)\n",
    "mean_con_mat_ADHD_C = np.mean(con_mat_ADHD_C, axis = 0)\n",
    "\n",
    "con_mat_ADHD_I = np.array(con_mat_ADHD_I)\n",
    "mean_con_mat_ADHD_I = np.mean(con_mat_ADHD_I, axis = 0)\n",
    "\n",
    "np.savetxt('UMCD_dataset/ADHD200_CC200/mean_connectivity_matrix_TD.txt', mean_con_mat_TD, delimiter=',') \n",
    "np.savetxt('UMCD_dataset/ADHD200_CC200/mean_connectivity_matrix_ADHD_C.txt', mean_con_mat_ADHD_C, delimiter=',') \n",
    "np.savetxt('UMCD_dataset/ADHD200_CC200/mean_connectivity_matrix_ADHD_I.txt', mean_con_mat_ADHD_I, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typically Developing:  [  4  27  60 108 126 128 134 145 147 166]\n",
      "ADHD_Combined:  [  4  27  60 108 126 128 134 145 147 166]\n",
      "ADHD-Inattentive:  [  4  27  60 108 126 128 134 145 147 166]\n"
     ]
    }
   ],
   "source": [
    "#label = np.genfromtxt('UMCD_dataset/ADHD200_CC200/ADHD200_CC200/KKI_1043241_region_names_abbrev_file.txt', dtype='str')\n",
    "label = np.array([i for i in range(mean_con_mat_TD.shape[0])])\n",
    "\n",
    "ind = cor_cluster(mean_con_mat_TD, label, threshold = 0.55)\n",
    "#print(np.unique(ind, return_counts=True))\n",
    "TD_region = label[ind == 77][0:10]\n",
    "\n",
    "ind = cor_cluster(mean_con_mat_ADHD_C, label, threshold = 0.55)\n",
    "#print(np.unique(ind, return_counts=True))\n",
    "ADHD_C_region = label[ind == 65][0:10]\n",
    "\n",
    "ind = cor_cluster(mean_con_mat_ADHD_I, label, threshold = 0.55)\n",
    "#print(np.unique(ind, return_counts=True))\n",
    "ADHD_I_region = label[ind == 61][0:10]\n",
    "\n",
    "print('Typically Developing: ', TD_region)\n",
    "print('ADHD_Combined: ', ADHD_C_region)\n",
    "print('ADHD-Inattentive: ', ADHD_I_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRURIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_pool\n",
       "Healthy      15\n",
       "Psoriasis    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_list = pd.read_csv('UMCD_dataset/PRURIM/PRURIM_list.csv', header = 0)\n",
    "sub_id = sub_list['network_name']\n",
    "\n",
    "sub_list.value_counts('subject_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_H = []\n",
    "con_mat_P = []\n",
    "\n",
    "for i in sub_id:\n",
    "    fname = 'UMCD_dataset/PRURIM/PRURIM/' + i + '_connectivity_matrix_file.txt'\n",
    "    if not os.path.isfile(fname):\n",
    "        continue\n",
    "    con_mat = np.loadtxt(fname)\n",
    "    np.fill_diagonal(con_mat, 1) \n",
    "    if sub_list.loc[sub_list['network_name'] == i].subject_pool.item() == 'Healthy':\n",
    "        con_mat_H.append(con_mat)\n",
    "    elif sub_list.loc[sub_list['network_name'] == i].subject_pool.item() == 'Psoriasis':\n",
    "        con_mat_P.append(con_mat)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "con_mat_H = np.array(con_mat_H)\n",
    "mean_con_mat_H = np.mean(con_mat_H, axis = 0)\n",
    "\n",
    "con_mat_P = np.array(con_mat_P)\n",
    "mean_con_mat_P= np.mean(con_mat_P, axis = 0)\n",
    "\n",
    "np.savetxt('UMCD_dataset/PRURIM/mean_connectivity_matrix_Healthy.txt', mean_con_mat_H, delimiter=',') \n",
    "np.savetxt('UMCD_dataset/PRURIM/mean_connectivity_matrix_Psoriasis.txt', mean_con_mat_P, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy:  [16 17 28 29 62 63 78 79 80 81]\n",
      "Psoriasis:  [42 43 44 45 46 47 48 49 50 51]\n"
     ]
    }
   ],
   "source": [
    "label = np.array([i for i in range(mean_con_mat_H.shape[0])])\n",
    "\n",
    "ind = cor_cluster(mean_con_mat_H, label, threshold = 0.65)\n",
    "#print(np.unique(ind, return_counts=True))\n",
    "H_region = label[ind == 15][0:10]\n",
    "\n",
    "ind = cor_cluster(mean_con_mat_P, label, threshold = 0.5)\n",
    "#print(np.unique(ind, return_counts=True))\n",
    "P_region = label[ind == 8][0:10]\n",
    "\n",
    "print('Healthy: ', H_region)\n",
    "print('Psoriasis: ', P_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCSF_MAC_PSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_pool\n",
       "Control                           40\n",
       "Progressive Supranuclear Palsy    24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_list = pd.read_csv('UMCD_dataset/UCSF_MAC_PSP/UCSF_MAC_PSP_list.csv', header = 0)\n",
    "sub_id = sub_list['network_name']\n",
    "\n",
    "sub_list.value_counts('subject_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat_CON = []\n",
    "con_mat_PSP = []\n",
    "\n",
    "for i in sub_id:\n",
    "    fname = 'UMCD_dataset/UCSF_MAC_PSP/UCSF_MAC_PSP/' + i + '_connectivity_matrix_file.txt'\n",
    "    if not os.path.isfile(fname):\n",
    "        continue\n",
    "    con_mat = np.loadtxt(fname)\n",
    "    np.fill_diagonal(con_mat, 1) \n",
    "    if sub_list.loc[sub_list['network_name'] == i].subject_pool.item() == 'Control':\n",
    "        con_mat_CON.append(con_mat)\n",
    "    elif sub_list.loc[sub_list['network_name'] == i].subject_pool.item() == 'Progressive Supranuclear Palsy':\n",
    "        con_mat_PSP.append(con_mat)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "con_mat_CON = np.array(con_mat_CON)\n",
    "mean_con_mat_CON = np.mean(con_mat_CON, axis = 0)\n",
    "\n",
    "con_mat_PSP = np.array(con_mat_PSP)\n",
    "mean_con_mat_PSP= np.mean(con_mat_PSP, axis = 0)\n",
    "\n",
    "np.savetxt('UMCD_dataset/UCSF_MAC_PSP/mean_connectivity_matrix_Control.txt', mean_con_mat_CON, delimiter=',') \n",
    "np.savetxt('UMCD_dataset/UCSF_MAC_PSP/mean_connectivity_matrix_PSP.txt', mean_con_mat_PSP, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control:  [ 0  1  3  4  5  6  8  9 11 12]\n",
      "Progressive Supranuclear Palsy:  [ 0  1  5  7  8  9 13 15 16 18]\n"
     ]
    }
   ],
   "source": [
    "#label = np.genfromtxt('UMCD_dataset/UCSF_MAC_PSP/UCSF_MAC_PSP/HC_1_t1_region_names_abbrev_file.txt', dtype='str')\n",
    "label = np.array([i for i in range(mean_con_mat_PSP.shape[0])])\n",
    "\n",
    "ind = cor_cluster(mean_con_mat_CON, label, threshold = 0.5)\n",
    "#print(np.unique(ind, return_counts=True))\n",
    "CON_region = label[ind == 3][0:10]\n",
    "\n",
    "ind = cor_cluster(mean_con_mat_PSP, label, threshold = 0.75)\n",
    "#print(np.unique(ind, return_counts=True))\n",
    "PSP_region = label[ind == 2][0:10]\n",
    "\n",
    "\n",
    "print('Control: ', CON_region)\n",
    "print('Progressive Supranuclear Palsy: ', PSP_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('connectivity_matrix', con_mat_TD = con_mat_TD, con_mat_ADHD_C = con_mat_ADHD_C, \n",
    "                                con_mat_ADHD_I = con_mat_ADHD_I, con_mat_H = con_mat_H, \n",
    "                                con_mat_P = con_mat_P, con_mat_CON = con_mat_CON, \n",
    "                                con_mat_PSP = con_mat_PSP, TD_region = TD_region, ADHD_C_region = ADHD_C_region,\n",
    "                                ADHD_I_region = ADHD_I_region, H_region = H_region, P_region = P_region, \n",
    "                                CON_region = CON_region, PSP_region = PSP_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute LE mean and cov for the selected sub-network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.load('connectivity_matrix.npz') \n",
    "\n",
    "names = np.array(['TD', 'ADHD_C', 'ADHD_I', 'H', 'P', 'CON', 'PSP'])\n",
    "N = 10 # number of regions/nodes \n",
    "p = len(names)\n",
    "q = int(N*(N + 1)/2)\n",
    "\n",
    "\n",
    "M = np.zeros((p, N, N))\n",
    "Sigma = np.zeros((p, q, q))\n",
    "\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    tmp = mat['con_mat_' + name]\n",
    "    region = mat[name + '_region']\n",
    "    tmp1 = check_SPD(tmp[:, :, region][:, region])\n",
    "    #print(tmp[:, :, region][:, region].shape)\n",
    "    M[i] = FM_logE(tmp1)\n",
    "    #print(M[i].shape)\n",
    "    Sigma[i] = cov_logE(tmp1)\n",
    "    \n",
    "Sigma = check_SPD(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0047747733991427765,\n",
       " 0.0014275247074175077,\n",
       " 0.00023901388920429708,\n",
       " 0.0010000000000000093,\n",
       " 0.0010000000000000785,\n",
       " 0.0010000000000000388,\n",
       " 0.0010000000000001353]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.min(np.linalg.eigvalsh(x)) for x in Sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('LE_mean_cov', M = M, Sigma = Sigma, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
